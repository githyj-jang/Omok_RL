{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/githyj-jang/Omok_RL/blob/main/Omok_with_TD_Q_Learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHTFoIXkj2C9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 오목 보드 크기와 학습 파라미터 설정\n",
        "BOARD_SIZE = 15\n",
        "ALPHA = 0.1\n",
        "GAMMA = 0.9\n",
        "EPSILON = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q 테이블 초기화 함수"
      ],
      "metadata": {
        "id": "_5OksaQwxhwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_Q():\n",
        "    Q_table = {}\n",
        "    for i in range(BOARD_SIZE):\n",
        "        for j in range(BOARD_SIZE):\n",
        "            Q_table[(i, j)] = 0.0\n",
        "    return Q_table"
      ],
      "metadata": {
        "id": "FxJAEqboxazK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 행동 선택 함수 (ε-탐욕 정책)"
      ],
      "metadata": {
        "id": "atybr4uLxlDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(state, available_actions, Q_table):\n",
        "    if random.uniform(0, 1) < EPSILON:\n",
        "        return random.choice(available_actions)  # 탐험\n",
        "    else:\n",
        "        q_values = [Q_table[action] for action in available_actions]\n",
        "        return available_actions[np.argmax(q_values)]  # 최적 행동 선택"
      ],
      "metadata": {
        "id": "vJ02BJenxcth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q 값 업데이트 함수"
      ],
      "metadata": {
        "id": "PJ30AnvgxoHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_Q(Q_table, state, action, reward, next_state, next_available_actions, done):\n",
        "    best_next_action = max([Q_table[next_action] for next_action in next_available_actions]) if not done else 0\n",
        "    Q_table[action] += ALPHA * (reward + GAMMA * best_next_action - Q_table[action])"
      ],
      "metadata": {
        "id": "S3ST7-fqxqe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가능한 행동 반환 함수"
      ],
      "metadata": {
        "id": "27WRlRWZx5bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_available_actions(board):\n",
        "    return [(i, j) for i in range(BOARD_SIZE) for j in range(BOARD_SIZE) if board[i][j] == 0]"
      ],
      "metadata": {
        "id": "HsKrUhOTx99r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 게임 종료 여부 체크 함수 (승리 또는 무승부)"
      ],
      "metadata": {
        "id": "48Go0nD-yAEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_terminal_state(board):\n",
        "    return check_win(board, 1) or check_win(board, -1) or all(all(cell != 0 for cell in row) for row in board)"
      ],
      "metadata": {
        "id": "K6H6JqxnyCl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 승리 조건 체크 함수"
      ],
      "metadata": {
        "id": "XbrEzJg7yErm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_win(board, player):\n",
        "    def check_direction(x, y, dx, dy):\n",
        "        count = 0\n",
        "        for _ in range(5):\n",
        "            if 0 <= x < BOARD_SIZE and 0 <= y < BOARD_SIZE and board[x][y] == player:\n",
        "                count += 1\n",
        "            else:\n",
        "                break\n",
        "            x += dx\n",
        "            y += dy\n",
        "        return count == 5\n",
        "\n",
        "    for i in range(BOARD_SIZE):\n",
        "        for j in range(BOARD_SIZE):\n",
        "            if (check_direction(i, j, 1, 0) or  # 가로\n",
        "                check_direction(i, j, 0, 1) or  # 세로\n",
        "                check_direction(i, j, 1, 1) or  # 대각선 (\\)\n",
        "                check_direction(i, j, 1, -1)):  # 대각선 (/)\n",
        "                return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "8feMnq9xyGn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 연속된 돌의 수 계산 함수"
      ],
      "metadata": {
        "id": "gAyjFQcCyI00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_consecutive_stones(board, player, x, y, dx, dy):\n",
        "    count = 0\n",
        "    for _ in range(5):\n",
        "        if 0 <= x < BOARD_SIZE and 0 <= y < BOARD_SIZE and board[x][y] == player:\n",
        "            count += 1\n",
        "        else:\n",
        "            break\n",
        "        x += dx\n",
        "        y += dy\n",
        "    return count"
      ],
      "metadata": {
        "id": "wr7V1rZ_yLCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 보상 계산 함수"
      ],
      "metadata": {
        "id": "HPFJdl5SyMw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reward(board, player, action):\n",
        "    x, y = action\n",
        "    reward = 0\n",
        "\n",
        "    if check_win(board, player):\n",
        "        return 1  # 승리 시 보상\n",
        "    if check_win(board, -player):\n",
        "        return -1  # 패배 시 보상\n",
        "\n",
        "    directions = [(1, 0), (0, 1), (1, 1), (1, -1)]\n",
        "\n",
        "    for dx, dy in directions:\n",
        "        count_player = count_consecutive_stones(board, player, x, y, dx, dy)\n",
        "        count_opponent = count_consecutive_stones(board, -player, x, y, dx, dy)\n",
        "\n",
        "        # 연속된 돌의 수에 따라 보상 부여\n",
        "        if count_player == 4:\n",
        "            reward += 0.5  # 4개의 연속된 돌을 놓는다면 큰 보상\n",
        "        elif count_player == 3:\n",
        "            reward += 0.2  # 3개의 연속된 돌을 놓는다면 보상\n",
        "        elif count_player == 2:\n",
        "            reward += 0.1  # 2개의 연속된 돌을 놓는다면 작은 보상\n",
        "\n",
        "        # 상대방의 연속된 돌을 막는다면 보상\n",
        "        if count_opponent == 4:\n",
        "            reward += 0.5\n",
        "        elif count_opponent == 3:\n",
        "            reward += 0.2\n",
        "        elif count_opponent == 2:\n",
        "            reward += 0.1\n",
        "\n",
        "    return reward"
      ],
      "metadata": {
        "id": "ay_3aDZuyOzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오목 게임 학습"
      ],
      "metadata": {
        "id": "9mvZbSHByTdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q_table = initialize_Q()\n",
        "\n",
        "for episode in range(10000):  # 에피소드 수\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE))\n",
        "    done = False\n",
        "    player = 1  # 플레이어 1부터 시작\n",
        "\n",
        "    while not done:\n",
        "        state = board.copy()\n",
        "        available_actions = get_available_actions(board)\n",
        "        action = choose_action(state, available_actions, Q_table)\n",
        "        board[action] = player\n",
        "\n",
        "        reward = get_reward(board, player, action)\n",
        "        done = is_terminal_state(board)\n",
        "        next_state = board.copy()\n",
        "        next_available_actions = get_available_actions(board)\n",
        "\n",
        "        update_Q(Q_table, state, action, reward, next_state, next_available_actions, done)\n",
        "\n",
        "        state = next_state\n",
        "        player *= -1  # 플레이어 변경"
      ],
      "metadata": {
        "id": "VJQgSb2JyVog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   player 1 -> 학습된 모델을 따름 player 2 랜덤 선택\n",
        "*   player 1 , 2 학습된 모델을 따름\n",
        "\n"
      ],
      "metadata": {
        "id": "dQMv49e19ZUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action_learn(state, available_actions, Q_table):\n",
        "    q_values = [Q_table[action] for action in available_actions]\n",
        "    return available_actions[np.argmax(q_values)]\n",
        "\n",
        "def play_game_1(Q_table):\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE))\n",
        "    done = False\n",
        "    player = 1  # 플레이어 1부터 시작\n",
        "\n",
        "    while not done:\n",
        "        state = board.copy()\n",
        "        available_actions = get_available_actions(board)\n",
        "\n",
        "        if player == 1:\n",
        "            action = choose_action(state, available_actions, Q_table)\n",
        "        elif player == -1:  # player 2가 랜덤하게 행동\n",
        "            action = random.choice(available_actions)\n",
        "\n",
        "        board[action] = player\n",
        "        done = is_terminal_state(board)\n",
        "        player *= -1  # 플레이어 변경\n",
        "\n",
        "    return check_win(board, 1), check_win(board, -1), all(all(cell != 0 for cell in row) for row in board)\n",
        "\n",
        "# 게임 플레이 및 결과 계산\n",
        "def evaluate_policy_1(Q_table, num_games):\n",
        "    win_count_p1 = 0\n",
        "    win_count_p2 = 0\n",
        "    draw_count = 0\n",
        "\n",
        "    for _ in range(num_games):\n",
        "        p1_win, p2_win, draw = play_game_1(Q_table)\n",
        "        if p1_win:\n",
        "            win_count_p1 += 1\n",
        "        elif p2_win:\n",
        "            win_count_p2 += 1\n",
        "        elif draw:\n",
        "            draw_count += 1\n",
        "\n",
        "    return win_count_p1, win_count_p2, draw_count\n",
        "\n",
        "# policy를 따르는 user 1과 랜덤하게 행동하는 user 2의 승률 계산\n",
        "win_count_p1, win_count_p2, draw_count = evaluate_policy_1(Q_table, num_games=100)\n",
        "print(\"모델를 따르는 User 1의 승리 횟수:\", win_count_p1)\n",
        "print(\"랜덤하게 행동하는 User 2의 승리 횟수:\", win_count_p2)\n",
        "print(\"무승부 횟수:\", draw_count)\n"
      ],
      "metadata": {
        "id": "YIh4ZDqL9jsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97970164-4af7-4bc4-83df-f8ac2dc91754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델를 따르는 User 1의 승리 횟수: 100\n",
            "랜덤하게 행동하는 User 2의 승리 횟수: 0\n",
            "무승부 횟수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def play_game_2(Q_table):\n",
        "    board = np.zeros((BOARD_SIZE, BOARD_SIZE))\n",
        "    done = False\n",
        "    player = 1  # 플레이어 1부터 시작\n",
        "\n",
        "    while not done:\n",
        "        state = board.copy()\n",
        "        available_actions = get_available_actions(board)\n",
        "\n",
        "        action = choose_action_learn(state, available_actions, Q_table)\n",
        "\n",
        "        board[action] = player\n",
        "        done = is_terminal_state(board)\n",
        "        player *= -1  # 플레이어 변경\n",
        "\n",
        "    return check_win(board, 1), check_win(board, -1), all(all(cell != 0 for cell in row) for row in board)\n",
        "\n",
        "# 게임 플레이 및 결과 계산\n",
        "def evaluate_policy_2(Q_table, num_games):\n",
        "    win_count_p1 = 0\n",
        "    win_count_p2 = 0\n",
        "    draw_count = 0\n",
        "\n",
        "    for _ in range(num_games):\n",
        "        p1_win, p2_win, draw = play_game_2(Q_table)\n",
        "        if p1_win:\n",
        "            win_count_p1 += 1\n",
        "        elif p2_win:\n",
        "            win_count_p2 += 1\n",
        "        elif draw:\n",
        "            draw_count += 1\n",
        "\n",
        "    return win_count_p1, win_count_p2, draw_count\n",
        "\n",
        "win_count_p1, win_count_p2, draw_count = evaluate_policy_2(Q_table, num_games=100)\n",
        "print(\"모델를 따르는 User 1의 승리 횟수:\", win_count_p1)\n",
        "print(\"모델를 따르는 User 2의 승리 횟수:\", win_count_p2)\n",
        "print(\"무승부 횟수:\", draw_count)"
      ],
      "metadata": {
        "id": "dD_AezOM-5zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca390769-8f1d-4d7b-e9b2-b1e03c2d3248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델를 따르는 User 1의 승리 횟수: 100\n",
            "모델를 따르는 User 2의 승리 횟수: 0\n",
            "무승부 횟수: 0\n"
          ]
        }
      ]
    }
  ]
}